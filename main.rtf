{\rtf1\ansi\ansicpg1252\cocoartf2818
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww12720\viewh7800\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 from fastapi import FastAPI, Request\
import subprocess\
import whisperx\
import uuid\
import os\
\
app = FastAPI()\
\
@app.post("/transcribe")\
async def transcribe(request: Request):\
    data = await request.json()\
    youtube_url = data["youtube_url"]\
\
    uid = str(uuid.uuid4())\
    mp3_file = f"\{uid\}.mp3"\
\
    subprocess.run([\
        "yt-dlp", "--extract-audio", "--audio-format", "mp3",\
        "-o", mp3_file, youtube_url\
    ])\
\
    model = whisperx.load_model("large-v2", device="cpu")\
    audio = whisperx.load_audio(mp3_file)\
    result = model.transcribe(audio, batch_size=16)\
\
    diarize_model = whisperx.DiarizationPipeline(use_auth_token=os.environ.get("HF_TOKEN"))\
    diarize_segments = diarize_model(audio, result["segments"])\
    result["segments"] = whisperx.assign_word_speakers(diarize_segments, result["segments"])\
\
    os.remove(mp3_file)\
    return result\
}